---

title:  深度学习入门笔记
date: 2020-03-12
categories: DeepLearning
mathjax: true
tags:  
---

深度学习相关知识点

<!-- more -->



### 激活函数
<font color="red">激活函数必须使用非线性函数</font>
线性函数的问题在于，不管如何加深层数，总是存在与之等效的 "无隐藏层的神经网络"。

##### 隐藏层激活函数
* 阶跃函数
* ReLU函数
*  sigmoid                                        

##### 输出层激活函数
* 恒等函数-->  回归问题
* sigmoid ---> 二元分类
* softmax ---> 多元分类  

### 损失函数
损失函数是神经网络型性能的“恶劣层度”的指标，即当前的神经网络对监督数据在多大程度上不拟合，
在多大程度上不一致。
* 均方误差  
  
  
  $$
  E = \ce{1/2 \Sigma (y_k- t_k)^2}
  $$

$$
y_k 表示神经网络的输出，t_k表示监督数据， k表示数据的维度。
$$



* 交叉熵误差   

$$
E = - \Sigma t_k \log y_k
$$

$$
\log 表示以e为底的自然对数, y_k是神经网络的输出，t_k是正确解标签。
$$

$$
t_k中只有正确解标签的索引为1，其他均为0(one-hot表示)，
$$

交叉熵误差的值是由正确解标签所对应的输出结果决定的。                                                                                          









